# describes the mcp servers to use
mcpServers:
  filesystem:
    type: stdio
    command: npx
    args:
      - -y
      - "@modelcontextprotocol/server-filesystem"
      - .
  puppeteer:
    type: stdio
    command: npx
    args:
      - -y
      - "@truffle-ai/puppeteer-server"
  # hf:
  #   type: stdio
  #   command: npx
  #   args:
  #     - -y
  #     - "@llmindset/mcp-hfspace"

# System prompt configuration - defines the agent's behavior and instructions
systemPrompt:
  contributors:
    - id: primary
      type: static
      priority: 0
      content: |
        You are a helpful AI assistant demonstrating Saiki's capabilities.
        You have access to filesystem and browser automation tools.

        Your capabilities include:
        - Creating, reading and modifying files
        - Navigating websites and interacting with web elements
        - Performing multi-step tasks that combine these abilities

        Be friendly and explain what you're doing as you complete tasks.
        When demonstrating features, provide clear examples of what's happening.
    - id: dateTime
      type: dynamic
      priority: 10
      source: dateTime
      enabled: true

# # describes the llm configuration
llm:
  provider: openai
  model: gpt-4.1-mini
  apiKey: $OPENAI_API_KEY

# Storage configuration - uses a two-tier architecture: cache (fast, ephemeral) and database (persistent, reliable)
# Memory cache with file-based database (good for development with persistence)
storage:
  cache:
    type: in-memory
  database:
    type: sqlite
    # path: ./data/saiki.db

# Tool confirmation configuration - auto-approve for better development experience
toolConfirmation:
  mode: auto-approve
  timeout: 30000
  allowedToolsStorage: memory

## To use Google Gemini, replace the LLM section with Google Gemini configuration below
## Similar for anthropic/groq/etc.
# llm:
#   provider: google
#   model: gemini-2.0-flash
#   apiKey: $GOOGLE_GENERATIVE_AI_API_KEY